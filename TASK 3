import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier  # I like this for classification, but you could use KNN or whatever
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
# Load the iris data
iris = load_iris()
df = pd.DataFrame(iris.data, columns=iris.feature_names)
df['species'] = iris.target  # 0=setosa, 1=versicolor, 2=virginica

# Quick look
print("First few rows:\n", df.head())
print("\nShape:", df.shape)  # Should be (150, 5)
print("\nAny missing stuff?", df.isnull().sum())  # None, nice
print("\nSpecies counts:\n", df['species'].value_counts())  # 50 each, balanced

# Pairplot to visualize - this is cool for iris
sns.pairplot(df, hue='species', palette='Set1')
plt.show()  # You'll see clusters, setosa is easy to separate

# Boxplot for one feature, just to check
sns.boxplot(x='species', y='sepal length (cm)', data=df)
plt.title("Sepal Length by Species")
plt.show()
# Features and target
X = df.drop('species', axis=1)  # All measurements
y = df['species']

# Scale features - not strictly needed for RF but good practice
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)  # I usually print shapes to double-check
print("Scaled X shape:", X_scaled.shape)

# Split into train/test - 80/20 is fine
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)
print("Train size:", len(X_train), "Test size:", len(X_test))
# Model - nothing fancy
model = RandomForestClassifier(n_estimators=50, random_state=42)  # 50 trees should be enough

# Fit it
model.fit(X_train, y_train)
print("Model trained!")  # Just to know it ran
# Predict on test
y_pred = model.predict(X_test)

# Accuracy - should be high
acc = accuracy_score(y_test, y_pred)
print(f"Accuracy: {acc * 100:.2f}%")  # Usually 100% or close

# Full report
print("\nClassification Report:\n", classification_report(y_test, y_pred, target_names=iris.target_names))

# Confusion matrix - visual
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=iris.target_names, yticklabels=iris.target_names)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()  # Should have mostly zeros off-diagonal
# What's important?
importances = pd.Series(model.feature_importances_, index=iris.feature_names).sort_values(ascending=False)
print("\nFeature Importances:\n", importances)

# Quick plot
importances.plot(kind='bar')
plt.title("What Matters for Classification")
plt.show()  # Petal stuff usually tops
# Fake new flower - make it a DataFrame with column names to match what scaler saw
new_flower = pd.DataFrame([[5.1, 3.5, 1.4, 0.2]], columns=iris.feature_names)

new_scaled = scaler.transform(new_flower)
pred = model.predict(new_scaled)
print("Predicted species:", iris.target_names[pred[0]])
